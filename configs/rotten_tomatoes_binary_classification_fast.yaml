# Config to train nanogpt to predict sentiment of
# rotten tomatoes reviews
seed: 1337

model:
  name: Transformer
  block_size: 8
  batch_size: 32
  n_embd: 32
  n_layer: 4
  n_head: 4
  n_labels: 2
  dropout: 0.2
  hidden_size: 128

optimizer:
  learning_rate: 1e-3
  lr_scheduler:
    milestones: [1, 3]
    gamma: 0.5

dataset:
  name: "rotten_tomatoes"
  tokenizer: "bert-base-cased"

train:
  epochs: 4
  metric: accuracy
  num_examples: 5000

val:
  metric: accuracy
  num_examples: 1066
  num_samples: 3

eval:
  metric: accuracy
  num_examples: 1066
  num_samples: 3
